{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82e9dfff-4c90-46b3-8bc4-409d8ab2167f",
   "metadata": {},
   "source": [
    "# Face  Recognition  Attendance System "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8287aed5-7942-4a92-aba9-30ea8914dca0",
   "metadata": {},
   "source": [
    "1. cv2 captures a video frame from the webcam.\n",
    "\n",
    "2. numpy stores this frame as an array.\n",
    "\n",
    "3. face_recognition analyzes the frame to find faces and creates encodings for them.\n",
    "\n",
    "4. These encodings are compared to a list of numpy arrays of known faces.\n",
    "\n",
    "4. If a match is found:\n",
    "\n",
    "        datetime creates a timestamp.\n",
    "        \n",
    "        csv writes the name and timestamp to a file.\n",
    "        \n",
    "        pyttsx3 speaks the name aloud.\n",
    "\n",
    "5. cv2 draws a box and label around the face.\n",
    "\n",
    "6. cv2 displays the annotated video frame.\n",
    "\n",
    "All of this is housed inside a clean interface built by tkinter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dde48375-4393-4904-83de-7265c9a9f4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition \n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import pyttsx3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c40a5b-afd8-4e09-af97-aa62ed6c2045",
   "metadata": {},
   "source": [
    "Load the Known faces    and  convert into encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4b8e2a8d-4c96-403e-ad92-3a06b8e1daed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load known image\n",
    "# image of Prabhakar\n",
    "image_prabhakar = face_recognition.load_image_file(r\"C:\\Users\\91763\\Desktop\\mini_project_4th sem\\image\\prabhakar.jpg\")\n",
    "prabhakar_encoding = face_recognition.face_encodings(image_prabhakar)[0]\n",
    "# image of praphul\n",
    "image_praphul = face_recognition.load_image_file(r\"C:\\Users\\91763\\Desktop\\mini_project_4th sem\\image\\praphul.jpg\")\n",
    "praphul_encoding = face_recognition.face_encodings(image_praphul)[0]  \n",
    "# image of manish\n",
    "image_manish = face_recognition.load_image_file(r\"C:\\Users\\91763\\Desktop\\mini_project_4th sem\\image\\manish.jpg\")\n",
    "manish_encoding = face_recognition.face_encodings(image_manish)[0]\n",
    "# image of Aradhana mam\n",
    "image_ardhana = face_recognition.load_image_file(r\"C:\\Users\\91763\\Desktop\\mini_project_4th sem\\image\\ardhana_mam.jpg\")\n",
    "aradhana_encoding = face_recognition.face_encodings(image_ardhana)[0] \n",
    "# image of deepak\n",
    "image_deepak = face_recognition.load_image_file(r\"C:\\Users\\91763\\Desktop\\mini_project_4th sem\\image\\deepak.jpg\")\n",
    "deepak_encoding = face_recognition.face_encodings(image_deepak)[0]\n",
    "# image of aryan\n",
    "image_aryan = face_recognition.load_image_file(r\"C:\\Users\\91763\\Desktop\\mini_project_4th sem\\image\\aryan.jpg\")\n",
    "aryan_encoding = face_recognition.face_encodings(image_aryan)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152ee396-7493-4650-80f3-ccee69d2250b",
   "metadata": {},
   "source": [
    " store all the  encording faces  into the list  \n",
    "  also  Origional name of all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1ba7e6b6-5580-4e5d-8d18-94b76e55f795",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_face_encoding= [prabhakar_encoding, praphul_encoding, manish_encoding, aradhana_encoding,deepak_encoding,aryan_encoding]\n",
    "known_face_name=[ \"Prabhakar kumar Shahi\" , \"Praphul\",\"Manish\",\"Aradhana Mam\",\"Deepak\",\"Aryan Kumar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d4dd8f83-86a0-4018-b5d3-b5c19605e950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of expected students\n",
    "student= known_face_name.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "35655a8d-d8eb-42d9-8aae-04bec6a644bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_locations=[]\n",
    "face_encodings=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "78b8c861-3395-4e15-89d6-625940fc3c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "now= datetime.now()\n",
    "current_date= now.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "56863933-f14d-4f94-be8e-3df294386f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(f\"{current_date}.csv\", \"w+\", newline=\"\")\n",
    "lnwriter = csv.writer(f)\n",
    "spoken_names = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "24bd67a8-bea8-4daa-936b-201e86c77f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(0)\n",
    "ps = pyttsx3.init()\n",
    "while True:\n",
    "    _, frame = video_capture.read()\n",
    "    small_frame=cv2.resize(frame, (0,0), fx=0.25, fy=0.25)\n",
    "    rgb_small_frame= cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # recognize facess\n",
    "    face_locations= face_recognition.face_locations(rgb_small_frame)\n",
    "    face_encodings= face_recognition.face_encodings(rgb_small_frame , face_locations)\n",
    "    for face_encoding in face_encodings:\n",
    "        mathes = face_recognition.compare_faces(known_face_encoding, face_encoding)\n",
    "        face_distance = face_recognition.face_distance(known_face_encoding,face_encoding)\n",
    "        best_match_index= np.argmin(face_distance)\n",
    "        if(mathes[best_match_index]):\n",
    "            name = known_face_name[best_match_index]\n",
    "            if name not in spoken_names and name.strip():\n",
    "                    ps.say(name + \"  present  \")\n",
    "                    ps.runAndWait()\n",
    "                    spoken_names.add(name)\n",
    "\n",
    "        #add the text if persons is persent \n",
    "        if name in known_face_name:\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            bottomLeftCornerOfText= (10,100)\n",
    "            fontScale=1.5\n",
    "            fontColor= (255,0,0)\n",
    "            thickness=3\n",
    "            lineType= 2\n",
    "            cv2.putText(frame,name+\" present\",  bottomLeftCornerOfText, font,fontScale, thickness, lineType)\n",
    "            if name in student:\n",
    "                student.remove(name)\n",
    "                current_time = now.strftime(\"%H-%M -%S\")\n",
    "                lnwriter.writerow([name,current_time])\n",
    "\n",
    "    cv2.imshow(\"Attendance\", frame)\n",
    "    if cv2.waitKey(1)& 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "video_capture.release() \n",
    "cv2.destroyAllWindows()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f352a78-cd60-4e41-9ac7-1906010c7ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289b2978-19d9-44f1-8b80-32ea8e1f05df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
